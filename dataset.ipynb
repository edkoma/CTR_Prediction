{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "DATA_PATH = './data/data.txt'\n",
    "\n",
    "POP_FEATURES = ['instance_id', 'item_property_list', 'user_id',\n",
    "                'context_timestamp', 'context_id',\n",
    "                'predict_category_property', 'date']\n",
    "\n",
    "CATEGORICAL_FEATURES = ['item_id', 'item_brand_id', 'item_city_id', 'user_gender_id', 'user_occupation_id', 'shop_id']\n",
    "\n",
    "CONTINUOUS_FEATURES = ['item_price_level', 'item_sales_level', 'item_collected_level',\n",
    "                       'item_pv_level', 'user_age_level', 'user_star_level',\n",
    "                       'shop_review_num_level', 'shop_review_positive_rate',\n",
    "                       'shop_star_level', 'shop_score_service', 'shop_score_delivery',\n",
    "                       'shop_score_description']\n",
    "\n",
    "VECTOR_FEATURES = ['item_category_list']\n",
    "\n",
    "feature_buf = []\n",
    "\n",
    "\n",
    "def _pop_features(df):\n",
    "    for feature in POP_FEATURES:\n",
    "        df.pop(feature)\n",
    "\n",
    "\n",
    "def _generate_continuous_features(df):\n",
    "    \"\"\"连续特征\"\"\"\n",
    "    space = None\n",
    "    for feature in CONTINUOUS_FEATURES:\n",
    "        if feature in df.columns:\n",
    "            val = df[feature].values.reshape(-1, 1)\n",
    "            if space is None:\n",
    "                space = val\n",
    "            else:\n",
    "                space = np.hstack((space, val))\n",
    "            feature_buf.append(feature)\n",
    "    print(\"continuous shape = \", space.shape)\n",
    "    return space\n",
    "\n",
    "\n",
    "def _generate_categorical_features(df, space):\n",
    "    \"\"\"离散特征\"\"\"\n",
    "    oh_encoder = OneHotEncoder(sparse=True, categories='auto')\n",
    "    for feature in CATEGORICAL_FEATURES:\n",
    "        val = oh_encoder.fit_transform(df[feature].values.reshape((-1, 1))).toarray()\n",
    "        space = np.hstack((space, val))\n",
    "\n",
    "        for i in range(val.shape[1]):\n",
    "            feature_buf.append('{}_{}'.format(feature, i))\n",
    "    print(\"categorical shape = \", space.shape)\n",
    "    return space\n",
    "\n",
    "\n",
    "def _generate_vector_features(df, space):\n",
    "    \"\"\"向量特征\"\"\"\n",
    "    print(space.shape)\n",
    "    cv = CountVectorizer()\n",
    "    for feature in VECTOR_FEATURES:\n",
    "        val = cv.fit_transform(df[feature]).toarray()\n",
    "        space = np.hstack((space, val))\n",
    "\n",
    "        for i in range(val.shape[1]):\n",
    "            feature_buf.append('{}_{}'.format(feature, i))\n",
    "    print(\"vector shape = \", space.shape)\n",
    "    return space\n",
    "\n",
    "\n",
    "def _build_date_buf(date_pivot, left, right):\n",
    "    date_buf = []\n",
    "    for i in range(left, right):\n",
    "        date = date_pivot + pd.Timedelta(i, unit='d')\n",
    "        date_buf.append(date.strftime('%Y-%m-%d'))\n",
    "\n",
    "    return date_buf\n",
    "\n",
    "\n",
    "def _generate_historical_convrate(df):\n",
    "    \"\"\"历史转化率\"\"\"\n",
    "    unique_date = df['date'].unique()\n",
    "    col_list = [(['item_id'], 'item_convrate'), (['user_age_level', 'item_id'], 'age_item_convraterate')]\n",
    "\n",
    "    data_buf = []\n",
    "    for day in unique_date:\n",
    "        date_pivot = pd.to_datetime(day)\n",
    "        lag_days = _build_date_buf(date_pivot, -3, 0)\n",
    "\n",
    "        target_df = df[df['date'].isin([day])]\n",
    "        lag_df = df[df['date'].isin(lag_days)]\n",
    "\n",
    "        if lag_df.shape[0] == 0 or target_df.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        for cols, col_name in col_list:\n",
    "            \"\"\"每件商品的trade rate\"\"\"\n",
    "            lag_g = lag_df.groupby(cols).is_trade.mean().reset_index()\n",
    "\n",
    "            lag_cols = []\n",
    "            \"\"\"用extend因为cols是list\"\"\"\n",
    "            lag_cols.extend(cols)\n",
    "            lag_cols.append(col_name)\n",
    "\n",
    "            lag_g.columns = lag_cols\n",
    "            target_df = pd.merge(target_df, lag_g, on=cols, how='left').fillna(0)\n",
    "        data_buf.append(target_df)\n",
    "\n",
    "    hc_df = pd.concat(data_buf, axis=0).reset_index(drop=True)\n",
    "    print('historical convrate shape', hc_df.shape)\n",
    "    return hc_df\n",
    "\n",
    "\n",
    "def _make_instant_feature(df):\n",
    "    first, prev = -1, -1\n",
    "    first_buf, prev_buf, fif_min_buf = [], [], []\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        cur = row.context_timestamp\n",
    "\n",
    "        if first == -1:\n",
    "            first = row.context_timestamp\n",
    "\n",
    "        first_buf.append(cur - first)\n",
    "\n",
    "        if prev == -1:\n",
    "            prev_buf.append(0)\n",
    "            fif_min_buf.append(1)\n",
    "        else:\n",
    "            prev_buf.append(cur - prev)\n",
    "            if cur - prev <= 15 * 60:\n",
    "                fif_min_buf.append(fif_min_buf[-1] + 1)\n",
    "            else:\n",
    "                fif_min_buf.append(1)\n",
    "        prev = cur\n",
    "\n",
    "    df['first_to_now'] = first_buf\n",
    "    df['prev_to_now'] = prev_buf\n",
    "    df['recent_15_minutes'] = fif_min_buf\n",
    "\n",
    "    return df[['instance_id', 'first_to_now', 'prev_to_now', 'recent_15_minutes']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def _generate_instant_feature(df):\n",
    "    \"\"\"实时特征\"\"\"\n",
    "    sorted_df = df.sort_values('context_timestamp')\n",
    "\n",
    "    uig = sorted_df.groupby(['user_id', 'item_id'])\n",
    "    ins_g = uig[['instance_id', 'context_timestamp']].apply(_make_instant_feature)\n",
    "\n",
    "    ins_df = pd.merge(df, ins_g.reset_index(drop=True), on='instance_id')\n",
    "    print('instant feature shape', ins_df.shape)\n",
    "    return ins_df\n",
    "\n",
    "\n",
    "def generate_dataset(enhance=False):\n",
    "    df = pd.read_csv(DATA_PATH, sep=' ')\n",
    "    df['date'] = df['context_timestamp'].apply(lambda x: time.strftime('%Y-%m-%d', time.localtime(x)))\n",
    "\n",
    "    if enhance:\n",
    "        df = _generate_historical_convrate(df)\n",
    "        df = _generate_instant_feature(df)\n",
    "        CONTINUOUS_FEATURES.extend(['item_convrate', 'age_item_convraterate',\n",
    "                                    'first_to_now', 'prev_to_now', 'recent_15_minutes'])\n",
    "\n",
    "    y = df.pop('is_trade')\n",
    "    _pop_features(df)\n",
    "    space = _generate_continuous_features(df)\n",
    "    space = _generate_categorical_features(df, space)\n",
    "    X = _generate_vector_features(df, space)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test, feature_buf\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_dataset()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
